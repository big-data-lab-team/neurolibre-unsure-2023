

\section*{Conclusion}

% \TG{
%   \begin{itemize}
%     \item Summarize the key result: at inference, CNNs appear more stable than optimization methods. And the freesurfer variability is a lower bound because only fuzzy libmath was used. Mention key numbers. Refer to deepgoplus paper where cnns were also stable.
%     \item What does it mean? We expect CNN models to be less sensitive to software updates and environment changes. It's a good property for reproducibility.
%     \item Numerical variability might be masked by training. Future work: perturb training.
%   \end{itemize}
% }
The numerical uncertainty measured in CNN models SynthMorph and FastSurfer was substantially lower than in FreeSurfer recon-all, amounting to differences in the order of 4 to 6 significant bits in non-linearly registered images, and of up to 0.4 SÃ¸rensen-Dice score values in segmentations. 
% \Ines{specify across subjects?}
We believe that the high numerical uncertainty observed in FreeSurfer recon-all compared to CNN models results from the use of numerical optimization techniques in FreeSurfer recon-all while CNN models only involve low-dimensional convolutions, max-pooling operators, and simple activation functions. The low numerical uncertainty found in CNN models is consistent with previous observations in the very different task of protein function prediction~\cite{pepe2022numerical}. The numerical uncertainty found in FreeSurfer recon-all is also consistent with previous observations on FreeSurfer recon-all non-linear registration ~\cite{salari2021accurate} and segmentation~\cite{salari2020file}.
% It is important to note the uncertainty reported here is a lower bound for FreeSurfer recon-all's numerical uncertainty as instrumenting the whole program instead of just the libmath libraries would likely increase the uncertainty found.
% \Ines{mention that freesurfer noise is a lower bound?}

Our results suggest that neuroimaging CNN models are significantly more robust to small numerical perturbations than traditional image processing approaches. Therefore, we expect CNN results to be more reproducible across execution environments than traditional image processing approaches, implying better portability across software and hardware systems. 
% We also expect CNN results to be less sensitive to other types of small numerical perturbations---in particular acquisition noise---than traditional approaches.
% It was expected that SynthMorph be more numerically stable as CNNs are expected to be more resistant to software updates and environment changes CITE.
% This hypothesis holds, as the noise introduced by MCA into both methods was of the same magnitude as the type of noise generated by software updates and OS changes.
% Therefore, SynthMorph's numerical stability implies that SynthMorph can be used by different users across different systems without a change in results when using the same data and procedure.
% As this work and previous work~\cite{salari2021accurate} has shown, this is not the case for FreeSurfer, but having SynthMorph as a numerical stable alternative allows for studies that utilize it to obtain an additional measure of reproducibility.

Our results report on the numerical uncertainty resulting from CNN \emph{inference}, which is a relevant proxy for the uncertainty experienced by model end-users across different execution environments. However, the numerical uncertainty resulting from CNN \emph{training} was not measured in our experiments. We speculate that some of the numerical uncertainty observed in FreeSurfer recon-all results is intrinsic to the problems of subject-to-template non-linear registration and whole-brain segmentation, and should therefore manifest during CNN training. Mathematically, training CNN models involves numerical optimization in high-dimensional spaces, which we expect to be less numerically stable than CNN inference, and comparably stable to FreeSurfer recon-all. Should this assumption be accurate, the numerical uncertainty of predictions made by a sample of CNN models trained with Random Rounding should be substantial, which we plan to leverage in our future work by building efficient ensemble models capturing the numerical variability associated with non-linear registration or segmentation, possibly resulting in improved predictions. 

